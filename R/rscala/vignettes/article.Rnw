%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Integration of R and Scala Using rscala}

\documentclass[article]{jss}

\let\hlesc\hlstd \let\hlpps\hlstd \let\hllin\hlstd \let\hlslc\hlcom

\usepackage{lscape}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{booktabs}
\usepackage{paralist}
\usepackage{thumbpdf}
\usepackage[11pt]{moresize}
\usepackage{alltt}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage[T1]{fontenc}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
%\overfullrule=3mm
\usepackage{fancyvrb}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{xspace}

\newcommand{\rscala}{\pkg{rscala}\xspace}
\newcommand{\jvmr}{\pkg{jvmr}\xspace}
\newcommand{\rJava}{\pkg{rJava}\xspace}
\newcommand{\Rserve}{\pkg{Rserve}\xspace}
\newcommand{\Rcpp}{\pkg{Rcpp}\xspace}
\newcommand{\inline}{\pkg{Inline}\xspace}
\newcommand{\R}{\proglang{R}\xspace}
\newcommand{\Rscript}{\proglang{Rscript}\xspace}
\newcommand{\C}{\proglang{C}\xspace}
\newcommand{\Python}{\proglang{Python}\xspace}
\newcommand{\Csharp}{\proglang{C\#}\xspace}
\newcommand{\Ruby}{\proglang{Ruby}\xspace}
\newcommand{\Cpp}{\proglang{C++}\xspace}
\newcommand{\Scala}{\proglang{Scala}\xspace}
\newcommand{\Java}{\proglang{Java}\xspace}
\newcommand{\Fortran}{\proglang{Fortran}\xspace}
\newcommand{\BeanShell}{\pkg{BeanShell}\xspace}
\newcommand{\todo}[1]{\textbf{\textit{\colorbox{yellow}{\color{red}{TODO} \ldots #1}}}}

%% almost as usual
\author{David B.\ Dahl\\Brigham Young University}
\title{\textit{\Large Under Review\\\footnotesize Software Version: 2.5.3,\ \ Document ID: 2018-04-10}\\\vspace{5ex} Integration of \R and \Scala Using \rscala}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{David B. Dahl} %% comma-separated
\Plaintitle{Integration of R and Scala Using rscala} %% without formatting
\Shorttitle{Integration of \R and \Scala Using \rscala} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
The \rscala software is a simple, two-way bridge between \R and \Scala that
allows users to leverage the unique strengths of both languages in a
single project.  \Scala classes can be instantiated from \R and \Scala methods
can be called.  Arbitrary \Scala code can be executed on-the-fly from within
\R, inline \Scala functions can be defined, and callbacks to \R are supported.
\R packages can be developed using \Scala.  Conversely, \rscala also enables \R
code to be embedded within a \Scala application.  The \rscala package is
available on CRAN and has no dependencies beyond base \R and the \Scala
standard library.
}

\Keywords{Java Virtual Machine, JVM, language bridges, \R, \Scala}
\Plainkeywords{Java Virtual Machine, JVM, language bridges, R, Scala} %% without formatting

%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
\Submitdate{2017-08-22}
%% \Acceptdate{2012-06-04}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  David B.\ Dahl\\
  Professor\\ % and Associate Department Chair\\
  Department of Statistics\\
  Brigham Young University \\
  223 TMCB\\
  Provo, UT 84602\\
  E-mail: \email{dahl@stat.byu.edu}\\
  URL: \url{https://dahl.byu.edu}\\
}

%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/512/507-7103
%% Fax: +43/512/507-2851

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \renewcommand{\textfraction}{0.05}
%% \renewcommand{\topfraction}{0.95}
%% \renewcommand{\bottomfraction}{0.95}
%% \renewcommand{\floatpagefraction}{0.35}
%% \setcounter{totalnumber}{5}

\begin{document}

% Fix poorly formatted tilde.
\newcommand{\mytilde}{\lower.6ex\hbox{\char`\~}}
<<setup, include=FALSE>>=
library("knitr")
opts_chunk$set(fig.path='figure/latex-', cache.path='cache/latex-', cache=TRUE, size="small", out.columns=84, fig.align='center', fig.show='hold')
options(formatR.arrow=TRUE, width=90)
hook_source <- knit_hooks$get('source')
knit_hooks$set(source = function(x, options) {
  txt <- hook_source(x, options)
  # extend the default source hook
  gsub('~', '\\\\mytilde', txt)
})
#hook_output = knit_hooks$get('output')
#knit_hooks$set(output = function(x, options) {
#  if (!is.null(n <- options$out.lines)) {
#    x = unlist(strsplit(x, '\n'))
#    if (length(x) > n) {
#      # truncate the output
#      x = c(head(x, n), '....\n')
#    }
#    x = paste(x, collapse = '\n') # paste first n lines together
#  }
#  if (!is.null(n <- options$out.columns)) {
#    x = unlist(strsplit(x, '\n'))
#    probs <- nchar(x)>options$out.columns
#    x[probs] <- paste(substr(x[probs],1,options$out.columns-3), '...', sep="")
#    x = paste(x, collapse = '\n') # paste first n lines together
#  }
#  hook_output(x, options)
#})
@

%% include your article here, just as usual
%% Note that you should use the \pkg{}, \proglang{} and \code{} commands.

\section{Introduction}
\label{introduction}

This paper introduces \rscala \citep{rscala}, software that provides a bridge
between \R \citep{r} and \Scala \citep{scala}.  The goal of \rscala is to allow
users to leverage the unique strengths of \Scala and \R in a single program.
For example, \R packages can implement computationally-intensive algorithms in
\Scala and, conversely, \Scala applications can take advantage of the vast
array of statistical packages in \R.  Callbacks from embedded \Scala into \R
are supported.  The \rscala package is available on the Comprehensive \R
Archive Network (CRAN).  Also, \R can be embedded within a \Scala application
by adding a one-line dependency declaration in \pkg{Scala Build Tool} (SBT).

\Scala is a general-purpose programming language that is designed to strike a
balance between execution speed and programmer productivity.  \Scala programs
run on the Java Virtual Machine (JVM) at speeds comparable to \Java.  \Scala
features object-oriented, functional, and imperative programming paradigms,
affording developers flexibility in application design.  \Scala code can be
concise, thanks in part to type inference, higher-order functions, multiple
inheritance through traits, and a large collection of libraries.  \Scala also
supports pattern matching, operator overloading, optional and named parameters,
and string interpolation. \Scala encourages immutable data types and pure
functions (i.e., functions without side-effects) to simplify parallel
processing and unit testing. In short, the \Scala language implements many of
the most productive ideas in modern computing. To learn more about \Scala, we
suggest \emph{Programming in Scala} \citep{scalabook} as an excellent general
reference.

Because \Scala is flexible, concise, and quick to execute, it is emerging as an
important tool for scientific computing. For example, \pkg{Spark} \citep{spark}
is a cluster-computing framework for massive datasets written in \Scala.
Several books have been published recently on using \Scala for data science
\citep{a9781785281372}, scientific computing \citep{a9781785886942}, machine
learning \citep{a9781783558742}, and probabilistic programming
\citep{a9781617292330}.  We believe that \Scala deserves consideration when
looking for an efficient and convenient general-purpose programming language to
complement \R.

\R is a scripting language and environment developed by statisticians for
statistical computing and graphics.  Like \Scala, \R supports a functional
programming style and provides immutable data types.  \Scala programmers who
learn \R (and vice versa) will find many familiar concepts, despite the
syntactical differences.  \R has a massive user base of statisticians and over
11,000 actively-maintained packages on CRAN. Hence, the \Scala community has a
lot to gain from an integration with \R.

\R code can be very concise and expressive, but may run significantly slower
than compiled languages.  In fact, computationally intensive algorithms in \R
are typically implemented in compiled languages such as \C, \Cpp, \Fortran, and
\Java. The \rscala package adds \Scala to this list of high-performance
languages that can be used to write \R extensions. The \rscala package is
similar in concept to \Rcpp \citep{rcpp}, an \R integration for \C and \Cpp,
and \rJava \citep{rJava}, an \R integration for \Java. Though the \rscala
integration is not as comprehensive as \Rcpp and \rJava, it provides the
following important features to blend \R and \Scala.  First, \rscala allows
arbitrary \Scala snippets to be included within an \R script and \Scala objects
can be created and referenced directly within \R code. These features allow
users to integrate \Scala solutions in an existing \R workflow.  Second,
\rscala supports callbacks to \R from \Scala, which allow developers to
implement general, high-performance algorithms in \Scala (e.g., root finding
methods) based on user-supplied \R functions.  Third, \rscala supports
developing \R packages based on \Scala which allows \Scala developers to make
their work available to the \R community.  Finally, the \rscala software makes
it easy to incorporate \R in a \Scala application without even having to install
the \R package.  In sum, \rscala's feature-set makes it easy to exploit the
strengths of \R and \Scala in a single project.

We now discuss the implementation of \rscala and some relevant existing work.
Since \Scala code compiles to \Java byte code and runs on the JVM, one could
access \Scala from \R via \rJava and then benefit from the speed of shared
memory.  We originally implemented our \rscala bridge using this technique, but
later moved to a custom TCP/IP protocol for the following reasons.  First,
\rJava and \Scala's read-eval-print loop (REPL) are both implemented using
custom class loaders which, in our experience, conflict with each other in some
cases.  Second, since \rJava links to a single instance of the JVM, one
\rJava-based package can configure the JVM in a manner that is not compatible
with a second \rJava-based package.  The current \rscala package creates a new
instance of the JVM for each \Scala instance to avoid such conflicts.  Third,
the simplicity of no dependencies beyond \Scala's standard library and base \R
is appealing from a user's perspective.  Finally, callbacks in \rJava are
provided by the optional JRI component, which is only available if \R is built
as a shared library.  While this is the case on many platforms, it is not
universal and therefore callbacks could not be a guaranteed feature of \rscala
software if it were based on \rJava's JRI.

The discussion of the design of \rscala has so far focused on accessing \Scala
from \R.  The \rscala software also supports accessing \R from \Scala using the
same TCP/IP protocol.  This ability is an offshoot of the callback
functionality.  Since \Scala can call \Java libraries, those who are interested
in accessing \R from \Scala should also consider the \Java libraries \Rserve
\citep{rserve} and \pkg{RCaller} \citep{rcaller}.  \Rserve is also ``a TCP/IP
server which allows other programs to use facilities of \R''
(\url{http://www.rforge.net/Rserve}).  \Rserve clients are available for many
languages including \Java.  \Rserve is fast and provides a much richer API than
\rscala.  Like \rJava, however, \Rserve also requires that \R be compiled as a
shared library.  Also, Windows has some limitations such that \Rserve users are
advised not to ``use Windows unless you really have to''
(\url{http://www.rforge.net/Rserve/doc.html}).

The paper is organized as follows.  Section \ref{scalainr} describes using
\Scala from \R.  Some of the more important topics presented there include the
data types supported by \rscala, embedding \Scala snippets in an \R script,
accessing precompiled \Scala code from \R, defining inline \Scala functions,
and calling back into \R from embedded \Scala.  We also discuss how to develop
\R packages based on \Scala.  Section \ref{rinscala} describes using \R from
\Scala.  In both Sections\ \ref{scalainr} and \ref{rinscala}, concise examples
are provided to help describe the software's functionality.  Section
\ref{bootstrap} provides a case study to show how \Scala can easily be embedded
in \R to significantly reduce computation time for a simulation study.  We
conclude in Section \ref{conclusion} with future work.

\section[Accessing Scala in R]{Accessing \Scala in \R}
\label{scalainr}

This section provides a guide to accessing
\Scala from \R.  Those interested in the reverse --- accessing \R from \Scala
--- will also benefit from understanding the ideas presented here.

\subsection[Package and Scala installation]{Package and \Scala installation}

The \rscala package is available on the Comprehensive \R Archive Network (CRAN)
and can be installed by executing the following \R expression.

<<installPackage,eval=FALSE>>=
install.packages('rscala')
@

The \rscala package requires a \Scala installation in the 2.11.x or
2.12.x series.  A convenience function, \code{rscala::scalaInstall()}, is
provided to download and install \Scala in the user's home directory under the
\code{.rscala} directory. Because this is a user-level installation,
administrator privileges are not required.
System administrators can execute \code{rscala::scalaInstall(global=TRUE)},
which places Scala in the package's directory but requires a new installation
every time the package is updated.  To avoid this, system administrators can
install \Scala using their operating system's software management system (e.g.,
``\code{sudo apt install scala}'' on Debian/Ubuntu based systems).  Finally,
both administrators and users can use a manual installation as described on the
\Scala webpage.

\subsection[Instantiating a Scala interpreter in R]{Instantiating a \Scala interpreter in \R}

Load and attach the \rscala package in an \R session with the \code{library} function:

<<library>>=
library('rscala')
@

Create a \Scala instance using the \code{scala} function:

<<instantiateInterpreter,eval=FALSE>>=
scala()
@

<<instantiateInterpreterHidden,eval=TRUE,include=FALSE>>=
set.seed(2234)
scala(serialize.output=TRUE)
s %@% 'scala.util.Random.setSeed(3242)'
@

This implicitly makes the interpreter instance \code{s} available in the current
environment.  (The name can be customized with the \code{assign.name} option of the \code{scala} function.)
Information on the \Scala instance \code{s} is available using

<<scalaInfo,eval=FALSE>>=
scalaInfo(s)
@

Alternatively, details on the search for a suitable \Scala installation are
shown using

<<scalaInfo2,eval=FALSE>>=
scalaInfo(verbose=TRUE)
@

The \code{scala} function includes parameters to specify which \Scala
installation to use, the class path, whether matrices are in row-major or
column-major order, and several other settings.  The functions \code{scala2}
and \code{scala3} are equivalent to \code{scala} except they change the \code{mode}
option to customize how the bridge between \Scala and \R is established.
Interactive users may notice that the \code{scala} function feels faster because
it starts \Scala in the background.  Details on this and all
other functions are provided in the \R documentation for the package (e.g.,
\code{help(scala)}).

A \Scala session is only valid during the \R session in which it is created and
cannot be saved and restored through, for example, the \code{save} and
\code{load} functions.  Multiple \Scala instances can be created in the same \R
session.  Each \Scala instance runs independently with its own memory and
classpath.

The \R to \Scala bridge is not thread-safe so multiple \R processes/threads
should not access the same \Scala instance simultaneously.

\subsection[Calling Scala code from R]{Calling \Scala code from \R}

\subsubsection[Evaluating Scala snippets]{Evaluating \Scala snippets}

Snippets of \Scala code can be compiled and executed within an \R session using
several operators.  The most basic operator is \code{\%@\%} which evaluates
\Scala code and returns \code{NULL}.  Consider, for example, computing the
binomial coefficient ${10 \choose 3} = \prod_{i=1}^3 (10-i+1)/i$.  The code below
uses \Scala's \code{val} statement to define an immutable variable
\code{c_10_3}.  The expression \code{1 to 3} creates a range and the higher-order \code{map} method of the
range applies the function \code{(10-i+1) / i.toDouble} to each element \code{i} in the range.
Finally, the results are multiplied together by the \code{product} method.

<<evaluateScalaCodeSimple>>=
s %@% '
  val c_10_3 = (1 to 3).map( i => {
    (10-i+1) / i.toDouble
  }).product.toInt
'
@

This result is available in subsequent \Scala expressions as demonstrated
below.

<<evaluateScalaCodeSimple3>>=
s %@% 'print("10 choose 3 is " + c_10_3 + ".")'
@

Notice the side effect of printing \code{120} to the console.  The behavior for
console printing is controlled by the arguments \code{serialize.output},
\code{stdout}, and \code{stderr} of the \code{scala} function.  Default values
depend on the operating system and are set such that console output is
displayed in typical environments.

\Scala snippets can also be evaluated with the \code{\%\mytilde\%} operator.
Whereas \code{\%@\%} always returns \code{NULL}, \code{\%\mytilde\%} returns
the result of the last expression in the \Scala snippet.

<<evaluateScalaCodeSimple2>>=
tenChooseThree <- s %~% '(1 to 3).map( i => (10-i+1) / i.toDouble ).product'
tenChooseThree == choose(10,3)
@

\subsubsection{String interpolation}

The \rscala package features string interpolation for dynamic code snippets. \R
code placed between ``\code{@\{}'' and ``\code{\}}'' in a \Scala snippet is
evaluated and replaced by the string representation of the \R expression's
value before the \Scala snippet is executed. The \R code is executed in the
same environment (i.e., scope) as the evaluation request. A snippet can contain
any number of \code{@\{...\}} expressions.  For example,

<<evaluateScalaCodeStringInterpolation>>=
n <- 10
k <- 3
label <- "number of threesomes among ten people"
s %@% '
  val count = (1 to @{k}).foldLeft(1) { (prod,i) => prod * (@{n}-i+1)/i }
  println("The @{label} is " + count + ".")
'
@

Care is needed when using string interpolation because it relies on \R's
character representation on an \R expression.  One might be surprised, for
example, that the second expression in the next example is false. This is
because \code{@\{tenChooseThree\^{}20\}} is replaced by \code{6.191736e+20}
which, when parsed by the Scala compiler, leads to a slightly different value
than the calculated value.

<<evaluateScalaCodeInterpolationError>>=
s %~% 'math.pow(count, 20) == @{tenChooseThree^20}'
@

\subsubsection{Primitive and copyable types}

A \Scala result of class \code{Byte}, \code{Int}, \code{Double},
\code{Boolean}, or \code{String} is passed back to \R as a length-one vector of
raw, integer, double, logical, or character, respectively.  We refer to these
as the \emph{primitive types} supported by the \rscala package. Further, \Scala
arrays and rectangular arrays of arrays of the primitive types are passed to \R
as vectors and matrices of the equivalent \R types.  We call \emph{copyable
types} those types that are primitives, arrays of primitives, and rectangular
arrays of arrays of the primitive types.  The name emphasizes the fact that
these data structures are serialized and copied between \Scala and \R. This may
be a costly exercise for large data structures.

The code below produces a 2x5 matrix in \R.  If the \code{row.major} argument
of the \code{scala} function is changed to \code{FALSE} when defining the
\Scala instance \code{s}, the code produces a 5x2 matrix instead.

<<evaluateScalaCodeVector>>=
s %~% 'Array.fill(2)(Array.fill(5)(scala.util.Random.nextDouble))'
@

Table \ref{mappings} shows the mapping of primitive \Scala and \R types using
code examples.

\begin{table}[tb]
\scriptsize
\centering
\begin{tabular}{lll}
\toprule
     \textbf{Primitives} & \textbf{Vectors / Arrays} & \textbf{Matrices / Rectangular Arrays of Arrays} \\
\midrule
\noalign{\vspace{2ex}}
\code{a <- as.raw(3)} & \code{f <- as.raw(c(1, 2))} & \code{k <- matrix(as.raw(c(1, 2)), nrow=2)} \\
\code{val a = 3.toByte} & \code{val f = Array(1.toByte, 2.toByte)} & \code{val k = Array(Array(1.toByte), Array(2.toByte))} \\
\noalign{\vspace{4ex}}
\code{b <- TRUE} & \code{g <- c(TRUE, FALSE)} & \code{l <- matrix(c(TRUE, FALSE), nrow=2)} \\
\code{val b = true} & \code{val g = Array(true, false)} & \code{val l = Array(Array(true), Array(false))} \\
\noalign{\vspace{4ex}}
 \code{c <- 1L} & \code{h <- c(1L, 2L, 3L)} & \code{m <- matrix(c(1L, 2L), nrow=2)} \\
 \code{val c = 1} & \code{val h = Array(1, 2, 3)} & \code{val m = Array(Array(1), Array(2))} \\
\noalign{\vspace{4ex}}
 \code{d <- 1.0} & \code{i <- c(1.0, 2.0, 3.0)} & \code{n <- matrix(c(1.0, 2.0), nrow=2)} \\
 \code{val d = 1.0} & \code{val i = Array(1.0, 2.0, 3.0)} & \code{val n = Array(Array(1.0), Array(2.0))} \\
\noalign{\vspace{4ex}}
 \code{e <- "a"} & \code{j <- c("a", "b", "c")} & \code{o <- matrix(c("a", "b"), nrow=2)} \\
 \code{val e = "a"} & \code{val j = Array("a", "b", "c")} & \code{val o = Array(Array("a"), Array("b"))} \\
\noalign{\vspace{2ex}}
\bottomrule
\end{tabular}
\caption{\Scala values of type \code{Byte}, \code{Int}, \code{Double},
\code{Boolean}, or \code{String} (labeled \emph{primitives}), as well as arrays
and rectangular arrays of arrays of these types are copied from \Scala to \R as
length-one vectors, vectors, and matrices of the equivalent \R types.  These
are called \emph{copyable types}.  Each cell in the table contains two lines:
an \R expression (top) and the equivalent \Scala expression (bottom) with the
same identifier.  The matrix examples assume that the \code{scala} function is
called with \code{row.major=TRUE}.}
\label{mappings}
\end{table}

\subsubsection[Scala references]{\Scala references}

If the result of a \Scala expression is not a copyable type, then the
\code{\%\mytilde\%} operator will return a reference to a \Scala object that
can be used in subsequent evaluations.  If a \Scala reference is desired, even
when working with copyable types, use the \code{\%.\mytilde\%} operator.

In the next example, an instance of the class \code{scala.util.Random} is
created and, because the result is not a copyable type, a \Scala reference is
returned.  Second, a \Scala reference to an array of integers is returned,
despite the fact this is a copyable type, because the \code{\%.\mytilde\%}
operator is used.

<<evaluateScalaCodeReference>>=
rng <- s %~% 'new scala.util.Random()'
rng

oneToTenReference <- s %.~% 'Array.range(1,11)'
oneToTenReference
@

% In the next example, a \Scala reference is used via string interpolation to
% call methods of \Scala objects:
% 
% \clearpage
% <<evaluateScalaCodeReferenceInterpolation>>=
% s %~% '
%   @{rng}.setSeed(24234)
%   @{rng}.nextDouble()
% '
% 
% s %~% '@{oneToTenReference}.sum'
% @

\subsubsection{Getting and setting variables}

Values of copyable types and \Scala references can be obtained as the result of
evaluating a \Scala expression using the \code{\%\mytilde\%} and
\code{\%.\mytilde\%} operators.  The expression can be very complex or, as in
the examples below, merely the name of a \Scala identifier.

<<gettingUsingDollarSign1>>=
s %@% 'val fibSeq = Array[Double](0, 1, 1, 2, 3, 5, 8, 13, 21)'
fibSeqAsDouble  <- s %~%  'fibSeq'
fibSeqReference <- s %.~% 'fibSeq'
@

\Scala values can also be obtained using the \code{\$} operator and the
identifier name.  For example, the following both provide equivalent
definitions for \code{fibSeqAsDouble} above.

<<gettingUsingDollarSign2>>=
fibSeqAsDouble <- s$fibSeq
fibSeqAsDouble <- s$val('fibSeq')
@

Likewise, an equivalent definition for \code{fibSeqReference} is

<<gettingUsingDollarSign3>>=
fibSeqReference <- s$.val('fibSeq')
@

Note that \code{val} is a reserved word in \Scala. Therefore, using \code{val}
and \code{.val} does not conflict with any variable names in \Scala.  While
somewhat more verbose, the argument to \code{val} and \code{.val} can be a
literal or a variable, whereas the \code{\$} operator requires a literal.

Values of copyable types and \Scala references can be set in the \Scala session
using assignment with the \code{\$} operator, e.g.:

<<gettingUsingDollarSign4>>=
s$fibSeq <- c(0, 1, 1, 2, 3, 5, 8, 13, 21)
s$copyOfFibSeqReference <- fibSeqReference
@

\subsubsection{Instantiating objects}

\Scala objects can be instantiated in three ways.  The following example
demonstrates functionally equivalent ways of creating a new instance of
\code{scala.util.Random} with the seed set at \code{123}.

<<evaluateScalaCodeInstantiate>>=
seed <- 123L
rng <- s %.~% 'new scala.util.Random(@{seed})'
rng <- s$.scala.util.Random$new(seed)
rng <- s$do('scala.util.Random')$new(seed)
@

Each method differs in terms of flexibility, readability, and speed.  The first
is mostly \Scala code and therefore self-evident to a \Scala developer, but it
is the slowest and awkward when arguments are not easily set with string
interpolation.  The second (using \code{s\$.}) is concise, fast, and flexible
in the arguments.  The string literal following \code{s\$.} and before the
second \code{\$} (e.g., \code{scala.util.Random}) can be the name of any class
in the classpath.
(The period in \code{s\$.} is used to differentiate class names from variables names.)
The last method (using \code{s\$do}) is also fast and
flexible but is slightly awkward.  It has the added advantage, however, that
the class name given as the argument to \code{s\$do} can be a literal (as in
this example) or a variable.  Note that \code{do} is a reserved word in \Scala
and is therefore guaranteed not to conflict with a variable name.

\subsubsection[Accessing methods and variables of Scala objects]{Accessing methods and variables of \Scala objects}

Taking inspiration from \rJava's high-level \code{\$} operator, methods
associated with \Scala references can be called directly using the \code{\$}
operator, as shown below.

<<evaluateScalaCodeReference2>>=
rng$setSeed(24234L)
rng$nextInt(10L)
oneToTenReference$sum()
@

If the result of a method call on a \Scala reference is not a copyable type,
then a reference to a \Scala object is returned.  If a \Scala reference is
desired even when working with copyable types, add a final argument
\code{.AS.REFERENCE=TRUE}. For example,

<<evaluateScalaCodeReference3>>=
intReference <- rng$nextInt(10L, .AS.REFERENCE=TRUE)
@

The value of an instance variable may be accessed as if there was a method of
the same name taking no arguments.  For example, the value \code{self} in an
instance of \code{scala.util.Random} is access as

<<evaluateScalaCodeReference1>>=
rng$self()
@

If there are no arguments when calling a method of a \Scala reference, the
empty parentheses are excluded in the generated \Scala code.  These empty
parentheses are needed, however, when one intends to use the methods default
arguments.  In that class, use \code{.PARENTHESES=TRUE} when calling the
method.

\subsubsection{Calling methods of singleton objects}

In contrast to \Java, \Scala classes do not have static variables or methods.
Equivalent functionality is provided by singleton objects in \Scala.  A
companion object is a singleton object whose name is the same as a class.
Methods of singleton objects can be called in three ways.  For example,
consider the companion object \code{Array} to the class \code{Array}.  Its
\code{range} method creates an array of regularly-spaced elements.  The
following three statements are all functionally equivalent:

<<evaluateScalaCodeCompanion>>=
oneToTenReference <- s %.~% 'Array.range(1, 11)'
oneToTenReference <- s$.Array$range(1L, 11L, .AS.REFERENCE=TRUE)
oneToTenReference <- s$do('Array')$range(1L, 11L, .AS.REFERENCE=TRUE)
@

As for instantiating objects, each approach has its advantages in terms of
flexibility, readability, and speed.

% \subsubsection[Discovering methods and variables of Scala objects]{Discovering methods and variables of \Scala objects}
% 
% \Scala provides the \code{scalap} executable to list the methods of classes and
% companion objects.  Its output is available directly in \R using the
% \code{scalap} function.  For example, \code{scalap(s, 'scala.util.Random')} and \code{scalap(rng)} both
% display the following.
% 
% <<scalap1, out.lines=5>>=
% scalap(rng)
% @
% 
% The \rscala package also provide rudimentary tab-completion for method names of
% \Scala references.

\subsubsection[Method arguments, null references, and length-one vectors]{Method arguments, null references, and length-one vectors}

Arguments to a method of an object (as well as argument to \code{new}) can be
copyable types and \Scala references.  To pass a null reference of a particular
type, use the \code{scalaNull} function.  For example, \Java's
\code{java.lang.System} has a static \code{setProperties} method which takes a
null reference to \code{java.util.Properties} to clear the system properties,
e.g.:

<<nullAsArgument>>=
s$.java.lang.System$setProperties(scalaNull('java.util.Properties'))
@

\R has no scalar types but they are often used in \Scala.  As such, length-one
vectors have special semantics.  In the \R expression \code{rng\$nextInt(10L)},
the value \code{10L} is an integer vector of length one in \R, but is passed to
\Scala as \code{Int}, not \code{Array[Int]}.  This is the most natural and
convenient behavior.  If, however, an \R vector should always be passed as an
array --- despite the fact that it might be of length one --- wrap the vector
in a call to the \code{I} function.  This ensures that the vector is treated
``as is''.  For example, consider a singleton object with an \code{apply}
method that takes an array of any arbitrary type \code{T} and a value of type
\code{T}, and sets every element of the array to that value:

<<lengthOne>>=
setter <- s %.~% '
  object setter {
    def apply[T](x: Array[T], value: T) = x.indices.foreach { x(_) = value }
  }
  setter
'
@

When calling the \code{apply} method of the \code{setter} object, the first
argument must be an array.  Thus, if there is a potential that the \R vector is
length-one, it should be wrapped by the \code{I} function.  In the example
below, the first argument is wrapped by \code{I} and is therefore passed to
\Scala as an array.  The second argument is a length-one double vector in \R
yet is treated as a \code{Double} (instead of \code{Array[Double]}) because it
is \emph{not} wrapped by \code{I}:

<<lengthOne2>>=
arr <- s %.~% 'Array(math.Pi, math.E)'
arr$mkString("<", ", ", ">")
setter$apply(I(arr), 3)
arr$mkString("<", ", ", ">")
@

\subsubsection[The apply and update methods]{The \code{apply} and \code{update} methods}

\Scala users are aware of the ``compiler magic'' that injects calls to the
\code{apply} method of objects when no method is specified.  In the \rscala
package, this works for \Scala snippets, but the \code{apply} method must be
specified explicitly when using the \code{\$} operator.  For example, consider
an array of the starting elements of the Fibonacci sequence and the following
functionally-equivalent expressions:

<<evaluateScalaCodeApply>>=
fibSeqAsInt <- s %~% 'Array(0, 1, 1, 2, 3, 5, 8, 13, 21)'
fibSeqAsInt <- s %~% 'Array.apply(0, 1, 1, 2, 3, 5, 8, 13, 21)'
fibSeqAsInt <- s$.Array$apply(0L, 1L, 1L, 2L, 3L, 5L, 8L, 13L, 21L)
fibSeqAsInt <- s$do('Array')$apply(0L, 1L, 1L, 2L, 3L, 5L, 8L, 13L, 21L)
@

Likewise, the \code{update} method is automatically injected by the \Scala
compiler when appropriate, but must be explicit when using the \code{\$}
operator.  Consider, for example, assigning the value of $\pi$ to the second
element of the array using the following.  The last four statements are
functionally equivalent.

<<evaluateScalaCodeUpdate>>=
s %@% 'val fibSeq = Array[Double](0, 1, 1, 2, 3, 5, 8, 13, 21)'
fibSeqReference <- s %.~% 'fibSeq'
s %@% 'fibSeq(1) = math.Pi'
s$.fibSeq$update(1L, pi)
s$do('fibSeq')$update(1L, pi)
fibSeqReference$update(1L, pi)
@

The previous example also illustrates that the \code{s\$.} and \code{s\$do}
notations --- which were first introduced for object instantiation and calling
methods of singleton objects --- can also be used for existing \Scala values
(e.g., \code{fibSeq} above).

\subsubsection{Quoting method names}

\Scala has type parameterization which is similar but arguably more advanced
than generics in \Java and templates in \Cpp.  In many instances, the \Scala
compiler infers the type parameter, but the user may need or want to explicitly
provide it.  When using the \code{\$} operator, the method name with its type
parameter should be quoted to prevent parsing errors in \R.  The following
expressions are functionally equivalent.

<<evaluateScalaCodeApplyWithQuote>>=
fibSeqAsDouble <- s %~% 'Array[Double](0, 1, 1, 2, 3, 5, 8, 13, 21)'
fibSeqAsDouble <- s %~% 'Array.apply[Double](0, 1, 1, 2, 3, 5, 8, 13, 21)'
fibSeqAsDouble <- s$.Array$'apply[Double]'(0L, 1L, 1L, 2L, 3L, 5L, 8L, 13L, 21L)
fibSeqAsDouble <- s$do('Array')$'apply[Double]'(0L, 1L, 1L, 2L, 3L, 5L, 8L, 13L, 21L)
@

Note the quotes around \code{apply[Double]} used in the last two expressions.
Of course, since \R treats numeric literals as doubles, the simplest way to get
the same result from the \code{apply} method of the \code{Array} companion
object is

<<evaluateScalaCodeApplyWithQuoteSimple>>=
fibSeqAsDouble <- s$.Array$apply(0, 1, 1, 2, 3, 5, 8, 13, 21)
@

Likewise, names of \Scala methods may not be valid identifiers in \R and may
also need to be quoted to avoid parsing errors in R.  For example, note that
the method \code{:+} is quoted here:

<<quoteWhenNecessary>>=
list <- s$.List$apply(1L, 2L, 3L)
augmentedList <- list$':+'(100L)
paste0(augmentedList$toString(), " now contains 100.")
@

% \subsubsection[Interfacing with Java]{Interfacing with \Java}
% 
% \Scala runs on the Java Virtual Machine and since it supports instantiating
% \Java classes and calling object and static methods, the \rscala package
% automatically provides this support as well.  For example, the example below
% finds the system's time zone through a chain of calls using the standard \Java
% library:
% 
% <<javaVersion>>=
% s$.java.util.TimeZone$getDefault()$getDisplayName()
% @

\subsection[Defining inline Scala functions]{Defining inline \Scala functions}
\label{inline}

In addition to calling previously-compiled \Scala methods, the \rscala package
enables \Scala functions to be defined \emph{within} an \R session.  The
associated \Scala code is compiled on-the-fly and cached for subsequent
evaluation in the \R session.  This feature is inspired by the \R packages \Rcpp and
\pkg{inline} \citep{inline} for \C, \Cpp, and \Fortran.  We do not recommend that
long, complicated algorithms be implemented as inline \Scala functions, but
these functions can be helpful for implementing small tasks or writing dynamic
code to interface with existing \Scala code.

To demonstrate \Scala functions, consider computing the number of partitions of
$n$ items (i.e., the Bell number \citep{bell} of $n$).  This number is often
used for finite mixture models and random partition models (e.g.,
\citet{casella2014}).  First, consider this \R implementation of an efficient
algorithm based on the Bell triangle (also known as the Aitken's array or the
Peirce triangle):

<<bellUsingR>>=
bell.version1 <- function(n, format=c("character","integer","double","log")[3]) {
  n <- as.integer(n[1])
  if ( n <= 0 ) stop("'n' must be at least 1.")
  if ( n == 1 ) return(1)
  r1 <- r2 <- numeric(n)
  r1[1] <- 1
  for ( k in 2:n ) {
    r2[1] <- r1[k-1]
    for ( i in 2:k ) r2[i] <- r1[i-1] + r2[i-1]
    r1 <- r2
  }
  value <- r2[n]
  if ( format == "character" ) sprintf("%0.0f", value)
  else if ( format == "integer" ) as.integer(value)
  else if ( format == "double" ) value
  else if ( format == "log" ) log(value)
}
@

The \code{bell.version1} function performs calculations based on
double-precision floating-point arithmetic and provides \emph{exact} answers
for $n \le 22$, gives \emph{approximate} answers for $22 < n \le 218$, and
overflows for $n > 218$.  The \code{format} argument controls the function's
output.  Unfortunately, $n \le 218$ is quite limiting because sample sizes are
often much larger in practice.  The following \Scala function, defined within
the \R session, implements the same algorithm but allows $n$ to be greater than
$218$.

<<bellUsingScala>>=
bell.version2 <- function(n, format=c("character","integer","double","log")[3]) {
  n <- as.integer(n[1])
  if ( n <= 0 ) stop("'n' must be at least 1.")
  s %!% '
    var r1 = new Array[BigInt](n)
    var r2 = new Array[BigInt](n)
    r1(0) = BigInt(1)
    for ( k <- 1 until n ) {
      r2(0) = r1(k-1)
      for ( i <- 1 to k ) r2(i) = r1(i-1) + r2(i-1)
      val tmp = r1; r1 = r2; r2 = tmp
    }
    val value = r1(n-1)
    format match {
      case "character" => value.toString
      case "integer" => value.toInt
      case "double" => value.toDouble
      case "log" =>
        val blex = value.bitLength - 1022
        if ( blex > 0 ) math.log( (value >> blex).toDouble ) + blex * math.log(2)
        else math.log(value.toDouble)
    }
  '
}
@

There are a few minor differences between the \R and \Scala versions (e.g.,
\Scala uses zero-based indexing of arrays, syntactic differences between \R and
\Scala, and the \Scala version avoids the copying found in the \R version), but
the practical difference is that \code{bell.version2} uses infinite precision
integer arithmetic based on \Scala's builtin \code{BigInt} class.  Overflow
still occurs when transferring to \R using \code{format="integer"} or
\code{format="double"}, but there is no overflow for almost any $n$ when
\code{format="log"}, and the exact value is returned when
\code{format="character"}.  The sample code below shows that the \Scala
function produces exact integer calculations for large $n$.  (The timings saved
in \code{cpuFirstEval} will be used later in Section \ref{cpu}.)

<<callBellUsingScala>>=
cpuFirstEval <- system.time(
   bigNumber <- bell.version2(500, format="character")
)
cat(paste(strsplit(bigNumber, "(?<=.{80})", perl = TRUE)[[1]], collapse="\n"), "\n")
@

Take a closer look at the definition of the \code{bell.version2} function.  We
call this a \Scala function because it contains \code{s \%!\% '...'}, where
\code{s} is a \Scala instance and \code{'...'} represents a \Scala snippet.
The effect of the \code{\%!\%} operator is two-fold: i.~it automatically makes
the arguments of the enclosing function (namely, \code{n} and \code{format})
available in the \Scala snippet, although this can be customized with the
\code{[} operator (as explained below), and ii.~it caches the on-the-fly
compilation of the \Scala snippet to substantially improve speed for repeated
calls.  The \code{\%!\%} operator returns a copyable type or, if the result is
not a copyable type, a \Scala reference.  The \code{\%.!\%} operator is
identical except that it always returns a \Scala reference.

The consumer of a \Scala function does not need to know that the implementation
is written in \Scala, but the programmer of a \Scala function should bear in
mind a few items.  If an argument to a \Scala function is not a copyable type
or a \Scala references, it will become a \code{EphemeralReference} object that
can still be used in \R code executed by the \Scala function.  (This
functionality is demonstrated later.) The \code{scalaNull} function can be used
to pass a null reference of a particular type.  For example, an argument to a
\Scala function might be \code{rng = scalaNull("scala.util.Random")},
indicating a null reference to \code{scala.util.Random}.

Additional variables in the local environment can be automatically serialized
to \Scala by listing them after the \code{[} operator of the \Scala instance.
Conversely, if an argument is not needed in the \Scala implementation (because,
for example, it has already been processed in the \R code), the serialization
can be avoided by using the \code{drop} argument of the \code{[} operator.  So,
for example, we can make available new variables \code{x}, \code{y}, and
\code{z} and skip variables \code{a} and \code{b} using
\code{s["x","y","z",drop=c("a","b")] \%!\% '...'}.  The automatically generated
\Scala code for the conversion of variables can be displayed (for debugging
purposes) by setting the \code{show.snippet} option, e.g.,
\code{scalaSettings(s, show.snippet=TRUE)}.

\subsection[Callbacks into R from embedded Scala]{Callbacks into \R from embedded \Scala}

When a \Scala instance is created with the \code{scala} function, an instance
of the \Scala class \code{org.ddahl.rscala.RClient} is bound to the identifier
\code{R}.  This object provides access to the \R session from within the \Scala
instance.  The \code{RClient} class is thread-safe.  Its source code and
Scaladoc are located on GitHub: \url{https://github.com/dbdahl/rscala/}.

To assign a value to a variable in the \R session from \Scala, use the
\code{set} method:

<<setInScala>>=
s %@% '
  R.set("zone", java.util.TimeZone.getDefault.getDisplayName)
  R.set("atLeast8", scala.util.Properties.isJavaAtLeast("1.8"))
'
zone
atLeast8
@

\R variables can be accessed in \Scala using several methods.  The first method
is \code{get}. It returns a \code{Tuple2} where the first member is the \R
variable's value (statically typed as \code{Any}) and the second is a
\code{String} identifying the resulting \Scala type.  Consider the example
below in which the value of the \R variable \code{T} is obtained.  Although the
runtime type of \code{T} is \code{Boolean}, the static type is \code{Any}.  To
be useful, it will likely need to be cast to another type as demonstrated with
the call to \code{asInstanceOf[Boolean]} below.

<<getInScala>>=
s %@% '
  val result = R.get("T")
  println("The result is " + result)
  if ( result._1.asInstanceOf[Boolean] ) {
    println("Good, nobody messed with the value of T.")
  }
'
@

Instead of casting the result from the \code{get} method, it may be more
convenient to call a method that returns a specific type. The \code{RClient}
class includes a suite of methods whose names start with \code{get} and end in
$XY$, where $X \in \{$\code{R}, \code{I}, \code{D}, \code{L}, \code{S}$\}$ and
$Y \in \{$\code{0}, \code{1}, \code{2}$\}$.  The value of $X$ indicates whether
the result from \R should be interpreted as raw, integer, double, logical, or
character, respectively.  The value of $Y$ indicates whether the result should
be interpreted as a scalar, an array, or a rectangular array of arrays,
respectively.  This example uses the \code{getL0} method to return the value of
the variable \code{T} as a logical scalar value.

<<getInScala2>>=
s %@% 'if ( R.getL0("T") ) { println("Good, nobody messed with the value of T.") } '
@

\R expressions can be evaluated with a suite of methods whose names start with
\code{eval} and end in $XY$, where $X$ and $Y$ have the same meaning as in the
\code{get} methods.  In the example below, \R and \Scala are used together to
sample from a chi-square distribution with $100$ degrees of freedom.

<<evalInScala>>=
set.seed(324)
s %~% 'R.evalD1("rnorm(100, sd=3)").map(math.pow(_, 2)).sum'
@

The \code{RClient} class also provides the ability to call \R functions through
methods that start with \code{invoke} and end in $XY$ (as in the \code{get} and
\code{eval} methods).  For example, the previous example could also be
implemented as follows.

<<invokeInScala>>=
set.seed(324)
s %~% '
  val mean = 100
  R.invokeD1("rnorm", mean, "sd" -> 3).map(math.pow(_, 2)).sum
'
@

The example above demonstrates the use of \Scala's builtin notation for
creating pairs (e.g., \code{"sd" -> 3}) to provide named arguments to the \R
function invoked from \Scala.  The arguments to an \code{invoke} method can be
copyable types, \Scala references, and \code{EphemeralReference} objects, the
last being automatically generated in \Scala functions for all arguments that
are wrapped by the \code{II} function or that are not copyable types and not
\Scala references.  Note that a \code{EphemeralReference} object is only valid
within the \Scala function in which it is defined.  It can, however, be made
valid beyond the \Scala function by converting it to a
\code{PersistentReference} using \code{R.getReference(x)}, where \code{x} is a
\code{EphemeralReference} object.

A more interesting use case is calling a user-supplied \R function from \Scala.
First, consider an \R function that computes $f(n,\alpha)$, the expectation of
the Ewens($n,\alpha$) distribution, i.e., the expected number of clusters when
sampling $n$ observations from a discrete random measure obtained from the
Dirichlet process with mass parameter $\alpha$.

<<enc>>=
f <- function(n,alpha) sapply(alpha, function(a) sum(a / (1:n + a - 1)))
f(100, 1.0)
@

In a Bayesian analysis, the Ewens distribution is a prior distribution in
random partition models and $\alpha$ is a hyperparameter.  In the prior
elicitation process, practitioners may want to find the value of $\alpha$ that
corresponds to the expert's anticipated number of clusters.  Thus, the task is
to numerically solve $f(n,\alpha) = \mu$ for $\alpha$, given fixed values for
$n$ and $\mu$.  To be specific, suppose $n=1000$ and $\mu=10$. The value
$\alpha$ can be obtained using root finding methods.  Here, we demonstrate the
bisection method implemented as a \Scala function. The function's first
argument, \code{func}, takes a user-defined \R function.  Since this argument
is not a copyable type or a \Scala reference, it is passed to \Scala as an
\code{EphemeralReference}, which is subsequently used in the expression
\code{R.invokeD0(func, x)} to call the \R function.

<<rootFinding>>=
bisection <- function(func, lower=1.0, upper=1.0, epsilon=0.000000001) s %!% '
  def g(x: Double) = R.invokeD0(func, x)
  val (fLower, fUpper) = (g(lower), g(upper))
  if ( fLower * fUpper > 0 ) sys.error("lower and upper do not straddle the root.")
  @scala.annotation.tailrec
  def engine(l: Double, u: Double, fLower: Double, fUpper: Double): Double = {
    if ( math.abs( l - u ) <= epsilon ) ( l + u ) / 2
    else {
      val c = ( l + u ) / 2
      val fCenter = g(c)
      if ( fLower * fCenter < 0 ) engine(l, c, fLower, fCenter)
      else engine(c, u, fCenter, fUpper)
    }
  }
  engine(lower, upper, fLower, fUpper)
'

bisection(function(a) f(100, a) - 10, 0.1, 20)
@

The most important aspect of this example is found in the first line of the
\Scala function where the \code{invokeD0} method calls the \code{R} function
referenced by \code{func} and returns the result as a \code{Double}.

The \rscala package supports infinite recursion (subject to available
resources) between \R and \Scala.  For example, the \code{recursive.sum}
function below repeatedly calls itself from \Scala to compute $0+1+2+\ldots+n$.

<<recursion>>=
recursive.sum <- function(n=0L) s %!% '
  if ( n <= 0 ) 0 else n + R.invokeI0("recursive.sum", n - 1)
'
recursive.sum(10)
@

\subsection{Memory management}

The \rscala package ties into the garbage collectors of both \R and \Scala.  As
such, the user often does not need to think about memory management.  There are
a few important things to note, however.  First, the default maximum heap size
set by the Java Virtual Machine may not be sufficient.  Adjust the heap size
using the \code{scala} function's \code{heap.size} argument, or use the global
option \code{rscala.heap.maximum} (e.g.,
\code{options(rscala.heap.maximum="4G")}). The former takes precedence over the
latter.

Second, there is an
\href{https://issues.scala-lang.org/browse/SI-4331}{unresolved issue (SI-4331)}
with the \Scala REPL (read-eval-print-loop) where allocated memory cannot be
freed even if the same identifier is set to another value.  This issue prevents
memory from being recovered in \rscala when using the \code{\%\mytilde\%} and
\code{\%.\mytilde\%} operators, or when using the the \code{\$} assignment
operator.  This issue does not affect \Scala functions and calls to methods on
\Scala references.  Hence, we encourage developers to use functions and methods
for memory intensive applications.  As will be shown later, functions and
methods also enjoy faster execution than the equivalent code using the
\code{\%\mytilde\%} and \code{\%.\mytilde\%} operators.

\subsection{Speed considerations}
\label{cpu}

Section \ref{bootstrap} considers the easy of implementing and the execution speed of 
a simulation study in \R, \Cpp via \Rcpp, and \Scala via \rscala.  It is not a
comprehensive comparison of the performance of these languages.  For that, we refer
readers to benchmarks available on the web, including \citet{languageShootout}.
Here we wish to highlight performance characteristics of \rscala itself.

Every \Scala snippet associated with the \code{\%@\%}, \code{\%\mytilde\%}, and
\code{\%.\mytilde\%} operators is compiled at every invocation.  In contrast, a
\Scala snippet in a \Scala function (see Section \ref{inline})
and methods of Scala references are only compiled
the first time they are run.  Subsequent invocations are faster because
the compiled code is cached and re-used.  Recall that in Section \ref{inline}
the variable \code{cpuFirstEval} saved the system time associated with the
first invocation of the \Scala function \code{bell.version2}.

<<showCPUFirstEval>>=
cpuFirstEval
@

When we run the function again, we find the system time is substantially
reduced because the code does not need to be compiled.

<<callBellUsingScala2>>=
cpuSecondEval <- system.time(
   bigNumber <- bell.version2(500, format="character")
)
cpuSecondEval
cpuFirstEval['elapsed'] / cpuSecondEval['elapsed']
@

Methods of \Scala references also benefit from caching.  Consider, for example,
two calls to the method \code{nextGaussian} of an instance of
\code{scala.util.Random}.

<<methodsAreCached>>=
rng <- s$.scala.util.Random$new()
first  <- system.time( rng$nextGaussian() )['elapsed']
second <- system.time( rng$nextGaussian() )['elapsed']
c(first=first, second=second, ratio=first/second)
@

Beyond the one-time cost of compiling, calling methods of \Scala references
still involves a recurring invocation cost, some of which can be eliminated as
follows.  Call the desired method of the \Scala reference with an additional
trailing argument \code{.EVALUATE=FALSE} and store the resulting function,
e.g.:

<<makeFasterNextGaussian>>=
fasterNextGaussian <- rng$nextGaussian(.EVALUATE=FALSE)
@

The function \code{fasterNextGaussian} is optimized and has less overhead than
explicitly calling the \code{nextGaussian} method of a \Scala reference.  By
way of comparison, \rJava also provides two means to call the
\code{nextGaussian} method.  Suppose that \code{rngRJava} is the result of
instantiating an object of class \code{scala.util.Random} using \rJava.  The
high-level \code{\$} operator of \rJava can call this method using
\code{rngRJava$nextGaussian()}.  Alternatively, the \rJava's low-level
interface provides the \code{.jcall} function.  The next example and Table
\ref{overhead} compare the speed of \rscala's \code{rng\$nextGaussian()} and
its optimized \code{fasterNextGaussian()}, together with \rJava's two ways of
calling the same method.

<<benchmarkAgainstRJava>>=
library('rJava', verbose=FALSE, quietly=TRUE)
invisible(
  rJava::.jinit(
    list.files(file.path(scalaInfo(s)$home, "lib"), full.names=TRUE)
  )
)
rngRJava <- rJava::.jnew("scala.util.Random")
fasterNextGaussianRJava <- function() rJava::.jcall(rngRJava, "D", "nextGaussian")

if ( suppressWarnings(require('microbenchmark', quietly=TRUE)) ) {
  timings <- summary(microbenchmark(fasterNextGaussianRJava(), fasterNextGaussian(),
    rngRJava$nextGaussian(), rng$nextGaussian(), times=1000))
} else load('timings.RData')
@

<<benchmarkAgainstRJavaTable, echo=FALSE, results='asis'>>=
library(xtable)
units <- attr(timings,"unit")
reps <- timings[1,"neval"]
timings <- cbind(timings[,c("expr")],c("rJava","rscala","rJava","rscala"),timings[,c("lq","mean","median","uq")])
colnames(timings) <- c("Expression","Package","Q1","Mean","Median","Q3")
xtab <- xtable(timings, label="overhead")
caption(xtab) <- paste0("Comparison of execution time of various ways to call the \\code{nextGaussian} method of an instance of the \\code{scala.util.Random} class.  Since the method itself is relatively fast, the timings here are an indication of the overhead involved with the various techniques.  Each expression was evaluated ",reps," times and the results are in ",units,".")
print(xtab,include.rownames=FALSE,booktabs=TRUE,table.placement="t")
@

The results in Table \ref{overhead} indicate that \rJava's \code{.jcall}
interface is much faster than the other techniques.  We recommend that \rscala
users avoid calling \Scala code in long-running, tight inner loops where
millisecond delays can add up.

\subsection[Developing packages based on rscala]{Developing packages based on \rscala}

The \rscala package enables developers to use \Scala in their own \R packages
to implement computationally intensive algorithms.  For example, the
\pkg{shallot} \citep{shallotSoftware} and \pkg{bamboo} \citep{bambooSoftware}
packages on CRAN use \Scala via \rscala to implement statistical methodology of
their associated journal articles \citep{shallotPaper,bambooPaper}.  The
\pkg{shallot} package takes advantage of \rscala's callback functionality to
allow access a user-specific likelihood and sampling function.  Readers are
invited to study those examples in addition to our description here.

An \R package based on \rscala should include \code{rscala} in the
\code{Imports} field of the package's \code{DESCRIPTION} file. Also, add
\code{import(rscala)} to the \code{NAMESPACE} file.  Define an \code{.onLoad}
function which calls \code{.rscalaPackage(pkgname)}, where \code{pkgname} is
the package's name.  The \code{onLoad} function may be as simple as

<<onLoad, eval=FALSE>>=
.onLoad <- function(libname, pkgname) {
  .rscalaPackage(pkgname)
}
@

The \code{.rscalaPackage} function binds a \Scala instance to the identifier
\code{s} in the package's namespace using the \code{scala} function.
The default for the \code{mode} argument is \code{"parallel"}.
This instantiates a \Scala interpreter in the background and therefore has minimal delay
when the interpreter \code{s} is first used.  If, however, \Scala itself is not
already installed, the user is asked for permission to download and install
\Scala (using the \code{scalaInstall} function).  Analogous to \rJava's
\code{.jpackage} function, the \code{.rscalaPackage} function adds the JAR
files in the source package's \code{inst/java} directory to \Scala's classpath.
Since \Scala is binary-compatible only within major releases, package
developers are encouraged to cross-compile for releases 2.11 and 2.12
and to place compatible \Scala JAR files in 
\code{inst/java/scala-2.11} and \code{inst/java/scala-2.12}, respectively.  If
a package supports only specific major releases of \Scala, change the
\code{major.release} argument of the \code{.rscalaPackage} function.

The \code{.rscalaPackage} function takes several optional arguments.  The
\code{classpath.packages} argument allows the package to use the JAR files of
another package.  For example, the \pkg{shallot} package uses this argument to
import the Apache Commons Mathematics Library JAR
files distributed with the \R package \pkg{commonsMath} \citep{commonsMathSoftware}.  The rational is that JAR
files can be large and, by having them in a separate package, they do not need
to be updated as frequently.  The arguments \code{classpath.prepend} and
\code{classpath.append} provide fine-grained control over the classpath.  The
argument \code{snippet} provides \Scala expressions that will be evaluated when
\Scala is instantiated.  This feature is useful for definitions and import
statements.  Finally, other arguments to \code{.rscalaPackage} are passed
directly to the \code{scala} function.  This \code{.onLoad} function taken from
the \pkg{shallot} package demonstrates several of these optional arguments and
also shows a callback to \R so that random data generation in \Scala is based
on \R's random number seed.

<<onLoad2, eval=FALSE>>=
.onLoad <- function(libname, pkgname) {
  snippet <- '
    import org.apache.commons.math3.random.{ RandomDataGenerator => RDG }
    import org.ddahl.shallot._
    import parameter._
    import parameter.decay._
    import parameter.partition._
    import distribution._
    import mcmc._

    def rdg() = {
      val ints = R.evalI1("runif(2,-.Machine$integer.max,.Machine$integer.max)")
      val seed = ((ints(0).asInstanceOf[Long]) << 32) | (ints(1) & 0xffffffffL)
      val r = new RDG()
      r.reSeed(seed)
      r
    }

    // This circumvents a bug in the class loader on some versions of Scala/JVM.
    scala.util.Try {
      new org.apache.commons.math3.random.EmpiricalDistribution()
    }
  '
  ## Users may want to use 'options(rscala.heap.maximum="2G")'.
  .rscalaPackage(pkgname,classpath.packages="commonsMath",snippet=snippet)
}
@

A package's embedded \Scala instance should be terminated when the package is
unloaded by calling the \code{.rscalaPackageUnload} function in the
\code{.onUnload} hook as shown here.

<<onUnload, eval=FALSE>>=
.onUnload <- function(libpath) {
  .rscalaPackageUnload()
}
@

Because \rscala's syntax for calling precompiled code is very similar to
\rJava's high-level \code{\$} operator, developing a package based on \rscala
can be very familiar to those accustomed to \rJava.  Take, for example, CRAN's
\pkg{mailR} package: ``Interface to Apache Commons Email to send emails from
\R'' \citep{mailr}.  This package uses \rJava and its high-level \code{\$}
convenience operator.  As a proof of concept, we ported the \pkg{mailR} package
to \rscala, replacing the dependency on \rJava.  Version 0.6 of the \pkg{mailR}
package is available on GitHub at \url{https://github.com/rpremraj/mailR/} and
our port is at \url{https://github.com/dbdahl/mailR/}.  The port involved
changes to the \code{DESCRIPTION} file, the \code{NAMESPACE} file, and two
script files.  We deleted 16 lines, added 4 lines, and modified 15 lines.  Most
modifications were simple changes. For example,

<<mailR.rJava, eval=FALSE>>=
base_dir <- .jnew("java.io.File", normalizePath(getwd()))
@

became

<<mailR.rscala, eval=FALSE>>=
base_dir <- s$.java.io.File$new(normalizePath(getwd()))
@

The difference between the two versions can be viewed here:
\url{https://github.com/dbdahl/mailR/commit/feb911f}.  Of course, porting a
package that makes frequent use of \rJava's ``low-level interface'' (e.g., the
\code{.jcall} function) will require more changes.

The \pkg{bamboo} package was originally implemented in \rJava.  The original
\rJava code is commented out with equivalent \rscala code following immediately
after.  See, for example,
\url{https://github.com/dbdahl/bamboo/blob/master/R/bamboo.R}.  This example
also illustrates the difficulty in calling \Scala using \rJava since \Scala has
several features that do not map directly to \Java equivalents.  Often, the
developer is required to write \Java-friendly wrapper methods in \Scala that
hide advanced \Scala features.

\section[Accessing R in Scala]{Accessing \R in \Scala}
\label{rinscala}

So far we have demonstrated assessing \Scala from \R.  Conversely, \rscala can
also embed an \R interpreter in a \Scala application via the
\code{org.ddahl.rscala.RClient} class.  This is achieved by generalizing the
previously-discussed callback functionality.  In this case, however, there is
not an existing instance of the \R interpreter.  The \R client spawns an \R
instance, immediately starts the embedded \R server, and connects \R to \Scala.

The \code{RClient} class is thread-safe.  Source code and Scaladoc are located
on GitHub: \url{https://github.com/dbdahl/rscala/}.  As a convenience,
\rscala's JAR file is available in standard repositories for use by dependency
management systems.  To use \code{RClient} in a \Scala
application, simply add the following line to SBT's \code{build.sbt} file.

% There are two versions of the \R client. The \Java version
% (\code{org.ddahl.rscala.RClient4Java}) is a thin wrapper over the \Scala
% version (\code{org.ddahl.rscala.RClient}).  The wrapper hides \Scala-specific
% features and provides familiar Javadoc to \Java developers.

<<sbt, engine="scala",eval=FALSE>>=
libraryDependencies += "org.ddahl" %% "rscala" % "2.5.2"
@

Note that, since the necessary \R code is bundled in the JAR file, the \rscala
package does \emph{not} need to be installed in \R.  An embedded \R interpreter
is instantiated as follows:

<<scalaScript0,engine="scala",eval=FALSE>>=
val R = org.ddahl.rscala.RClient()
@

This assumes that the registry keys option was not disabled during the \R
installation on Windows.  On other operating systems, \code{R} is assumed to be
in the search path.  If these assumptions are not met or a particular
installation of \R is desired, the path to the \R executable may be specified
explicitly (e.g., \code{org.ddahl.rscala.RClient("/path/to/R/bin/R")}).  By
default, console output from \R is serialized back to \Scala.  The protocol
overhead may be reduced by using \code{serializeOutput=false} when
instantiating an \code{RClient}.

The \rscala package can be an easy and convenient way to access statistical
functions, facilitate calculations, manage data, and produce plots in a \Scala
application.  Consider, for example, wrapping \R's \code{qnorm} function to
define a method in \Scala by the same name.

<<scalaScript1qnorm,engine="scala",engine.path=scalaInfo(s)$cmd,engine.opts=paste0('-nc -cp ',scalaInfo(s)$classpath),comment="//",eval=(.Platform$OS.type != "windows")>>=
val R = org.ddahl.rscala.RClient()

def qnorm(x: Double, mean: Double = 0, sd: Double = 1, lowerTail: Boolean = true) = {
  R.invokeD0("qnorm", x, mean, sd, "lower.tail" -> lowerTail)
}

val alpha = 0.05
println(s"If Z is N(0,1), P(Z >= ${qnorm(alpha, lowerTail=false)}) = $alpha.")
@

The next example uses \R's dataset \code{eurodist} to compute the European city
that is closest, on average, to all other European cities.  While this
statistical calculation is easily implemented in \R, one can imagine a \Scala
application that needs to perform a more taxing calculation that leverages \R's
rich data-processing functions.

<<scalaScript1europe,engine="scala",engine.path=scalaInfo(s)$cmd,engine.opts=paste0('-nc -cp ',scalaInfo(s)$classpath),comment="//",eval=(.Platform$OS.type != "windows")>>=
val R = org.ddahl.rscala.RClient()
val distances = R.evalD2("as.matrix(eurodist)")
val cities = R.evalS1("attr(eurodist,'Labels')")
val centralCity = distances.map(_.sum).zip(cities).minBy(_._1)._2
println(s"Europe's central city is $centralCity.")
@

The \code{RClient} also enables a \Scala application to access \R's extensive
plotting facilities and to take advantage of the many packages available in \R.
As an example of a nontrivial \Scala application, consider a web site based on a
\Scala-based web framework such as \pkg{Play Framework}, \pkg{Scalatra},
\pkg{Xitrum}, or \pkg{Lift}.  Suppose part of the web application requires
plotting forecasted temperature data.  Rather than looking for a \Scala library
to obtain the weather forecasts and another library for plotting, the developer
might want to leverage knowledge of the \pkg{darksky} \citep{darksky},
\pkg{httr} \citep{httr}, and
\pkg{ggplot2} \citep{ggplot22} packages in \R.  One could simply execute an \R
script to run the desired code and read the result from the disk.  Another
solution is to connect to \R using \Rserve using its \Java client.  One could
go so far as to set up a server using, for example, RApache \citep{rapache},
CGIwithR \citep{cgi}, or Shiny \citep{shiny}, all of which require some initial
effort and ongoing maintenance beyond the effort required for the \Scala-based
web framework itself.  In contrast, the marginal cost of incorporating \rscala
is low, requiring only the declaration of the dependency on \rscala in the
project's \code{build.sbt} file (as shown earlier) and a standard installation
of \R with the \pkg{rscala}, \pkg{darksky}, \pkg{httr}, and \pkg{ggplot2} packages.  The web
application is hosted here:

\begin{center}
\url{https://dahl.byu.edu/software/rscala/temperature/}
\end{center}

The source code is available here:

\begin{center}
\url{https://github.com/dbdahl/rscala-example-temperature/}
\end{center}

Figure \ref{screenshot} shows a screenshot of the application.

\begin{figure}[tb]
\begin{center}
\includegraphics{screenshot.png}
\caption{Screenshot of a web application implemented in a \Scala-based
framework and accessing \R packages using \rscala.}
\label{screenshot}
\end{center}
\end{figure}

\pkg{Apache Spark}, a cluster-computing framework for massive datasets, is
another example of a \Scala application that might benefit from access to \R.
\pkg{Spark} provides an application programming interface to \Scala, \Java, \R,
and \Python.  \R users who are not already familiar with \Scala would be best
served by accessing \pkg{Spark} from \R using a dedicated package such as
\pkg{sparklyr} or \pkg{sparkr}.  \Scala developers, however, might prefer to
program directly with \pkg{Spark}'s Machine Learning Library (MLlib) in \Scala
and to supplement its functionality with \R through \rscala.  Recall that every
\code{RClient} has its own workspace, so several instances can be used to
overcome the single-threaded nature of \R.  One could, for example, use
\pkg{Apache Commons Pool} to manage a pool of \code{RClient} objects on each
worker node.  One potential limitation is the cost of pushing large datasets
over the TCP/IP bridge.

% We have provided support to a developer using \rscala in \pkg{Spark}.


% \subsection[Implementation of Scala code in R]{Implementation of \Scala code in \R}
% 
% The \code{scala} function starts a \Scala interpreter on the Java Virtual Machine using \R's
% \code{system2} function. The interpreter runs code that implements an asynchronous TCP/IP server
% and creates an instance of \code{scala.tools.nsc.interpreter.IMain} for \Scala's
% read-eval-print-loop (REPL). The TCP/IP
% server's port is randomly selected by default, but it can be fixed at a
% given value.  While the \Scala
% server is starting up, the \R component attempts to establish a connection using
% functions from the \pkg{base} \R package.  After connecting, the \R client interfaces with the
% server's REPL class by means of a custom protocol.
% 
% The \rscala package takes advantage of the \Scala REPL's ability to compile and
% execute \Scala code on-the-fly as well as set and get values of
% identifiers.  When a \Scala function is called for the first time (or when a
% particular method of a \Scala reference is called for the first time), it is
% compiled behind the scenes.  The compiled method is then
% cached and re-used for subsequent calls.  As an illustration, consider the code
% below and notice that the elapsed time is significantly less in the second call
% to the same method.
% 
% <<fasterAfterFirstTime>>=
% system.time( print(s$.sys$props("user.name")) )
% system.time( print(s$.sys$props("user.name")) )
% @
% 
% 
% 
% Callback functionality is implemented over the same TCP/IP sockets.
% Immediately after the \R client requests the execution of \Scala code, \R
% becomes a temporary, embedded server to allow the \Scala code to access the \R
% interpreter through the \code{R} object (an instance of the \code{RClient}
% class).  The embedded \R server interprets code and sets/gets values using the
% \code{parse}, \code{eval}, \code{assign}, and \code{get} functions.  After the
% \Scala server executes the \Scala code, it tells the embedded \R server to exit
% and the \Scala server resumes its usual behavior.

% \subsection{Bayesian logistic regression}
% \label{logisticRegression}
% 
% In this section we use a custom Markov chain Monte Carlo (MCMC) algorithm to
% fit a Bayesian logistic regression model in \R.  This model can also be
% estimated in \R through a variety of other algorithms using \R packages such as
% RStan \citep{stan-manual:2014}, rbugs \citep{Rbugs}, R2jags \citep{r2jags},
% rjags \citep{Rjags}, R2WinBUGS \citep{r2winbugs}, R2OpenBUGS
% \citep{r2openbugs}, and BRugs \citep{brugs}.  Our interest here,
% however, is \emph{not} to determine the best algorithm for Bayesian model
% fitting, but rather to compare the convenience and computational speed of
% \Scala, \C, and standard \R in implementing the same commonly-used,
% computationally-expensive algorithm.
% 
% Studies show that babies who breastfeed have a significantly reduced risk of
% health problems such as HIV, obesity, and neurological defects due to the
% fact that milk contains natural immune components that are not present in baby
% formula \citep{standby}.  Medical professionals have observed that premature
% babies take longer to learn how to breastfeed and many are not breastfeeding by
% the time they are ready to leave the hospital \citep{standby2}.  To quantify
% this relationship, a statistician wishes to fit a logistic regression model in
% which the probability of breastfeeding before leaving the hospital is modeled
% as a function of gestational age.  Data is available on $n=64$ infants where
% $y_i = 1$ if the baby is breastfeeding at departure and $x_i$ is the
% gestational age.  The model is
% \[
% \text{Pr}(y_i = 1) \ = \ \frac{1}{1+\exp\{-(\beta_0 + \beta_1 x_i)\}}
% \]
% where $\beta_0$ and $\beta_1$ are unknown parameters to estimate.  We assume
% independent Normal($-15$, $5$) and Normal($1$, $1$) priors on $\beta_0$ and
% $\beta_1$, respectively.
% 
% Since the model is not conjugate, we obtain samples from the joint posterior
% distribution using a Metropolis sampling algorithm with a uniform random walk.
% We examine the convenience and computational speed of running a single MCMC
% chain as well as simultaneously running 6 and 12 independent chains in
% parallel.  Recall that the test machine has 6 cores and hyperthreading is enabled
% making it appear that there are 12 cores.  We run the chains for 1,001,000
% iterations using the prior means as the starting state.  We discard the first
% 1,000 iterations for burn-in. This same MCMC algorithm is implemented in \Scala
% using \rscala, in \C using the \code{.C} interface, and in standard \R.  Note
% that a \C implementation using the \code{.Call} interface requires a more
% intimate knowledge of \R's \C API.  The implementations, data, and benchmarking
% code are all available in the online supplement.
% 
% \begin{table}[tb]
% \centering
% \begin{tabular}{r|rr|rr|rr}
%   \toprule
%  & \multicolumn{2}{c|}{1 core} & \multicolumn{2}{c|}{6 cores} & \multicolumn{2}{c}{12 cores} \\
% Language & Seconds & Ratio & Seconds & Ratio & Seconds & Ratio \\
%    \midrule
% \Scala using \rscala  & 1.12 & 1.00 & 0.29 & 1.00 & 0.18 & 1.00 \\
% \C using \code{.C}    & 1.48 & 1.32 & 0.31 & 1.09 & 0.24 & 1.36 \\
% Standard \R           & 15.79   & 14.11 & 3.78 & 13.15 & 2.70 & 15.08 \\
%    \bottomrule
% \end{tabular}
% \caption{Wall time and relative performance of three implementations of the same
% MCMC algorithm using 1, 6, and 12 cores based on a breastfeeding dataset with 64 samples and 6 levels of the predictor.}
% \label{mcmcInfant}
% \end{table}
% 
% The results are in Table~\ref{mcmcInfant} along with wall times and performance
% ratios (relative to \Scala).  Surprisingly, we find that the \Scala
% implementation is slightly faster than the \C implementation.  This may be due
% to the fact that the \Scala code uses a different library for evaluating the
% log of the binomial probabilities or because the \code{.C} interface is not as
% performant as the \code{.Call} interface.  The standard \R implementation is
% about 13-15 times slower.
% 
% The breastfeeding infants example involves $n=64$ observations at one of six
% unique values of the predictor.  To see how the results might change for larger
% datasets, we simulated a dataset of $n=20,000$ observations at one of 200
% unique values of the predictor.  The results are found in
% Table~\ref{mcmcSimulated}.  The most striking finding is that the standard \R
% implementation improves dramatically, now being only 1.4-1.6 times slower than
% the \Scala implementation.  The explanation is that the standard \R
% implementation, for this simulated data example, spends 72.5\% of the time in
% the function \code{dbinom}.  This function is implemented in \C using the
% \code{.Call} interface.  It is not surprising that a \C implementation
% and another implementation based mostly on \C (i.e., the standard \R
% implementation) perform similarly.
% 
% \begin{table}[tb]
% \centering
% \begin{tabular}{r|rr|rr|rr}
%   \toprule
%  & \multicolumn{2}{c|}{1 core} & \multicolumn{2}{c|}{6 cores} & \multicolumn{2}{c}{12 cores} \\
% Language & Seconds & Ratio & Seconds & Ratio & Seconds & Ratio \\
%    \midrule
% \Scala using \rscala  & 47.35 & 1.00 & 10.82 & 1.00 & 7.87 & 1.00 \\
% \C using \code{.C}    & 53.17 & 1.12 & 11.49 & 1.06 & 7.67 & 0.97 \\
% Standard \R           & 75.51 & 1.59 & 16.15 & 1.49 & 11.30 & 1.44 \\
%    \bottomrule
% \end{tabular}
% \caption{Wall time and relative performance of three implementations of the same MCMC
% algorithm using 1, 6, and 12 cores based on a simulated dataset with 20,000 samples and 200 levels of the predictor.}
% \label{mcmcSimulated}
% \end{table}

\section[Case study: Simulation study accelerated with rscala]{Case study: Simulation study accelerated with \rscala}
\label{bootstrap}

While the previously mentioned \pkg{shallot} and \pkg{bamboo} packages demonstrate the
ability to develop packages based on \rscala, we now demonstrate 
the ease with which computationally-intensive statistical procedures can be
implemented by embedding \Scala code in an \R script.  The algorithm is
embarrassingly parallel and we consider two means of parallelization: one using
\Scala's \code{Future} class and the other using \R's \pkg{parallel} package.
By way of comparison, we include a pure \R implementation of the same algorithm, 
and also an implementation that uses inline \Cpp code via the \Rcpp package. 
All four implementations define a
function that takes an \R sampling function as an argument.

We investigate a simulation study of the coverage probability of a bootstrap
confidence interval procedure.  Consider a population parameter
$\beta_1/\beta_2$, where $\beta_1$ and $\beta_2$ are population quantiles
associated with probabilities $p_1$ and $p_2$, respectively.  Based on a sample
of $n$ observations, a point estimator of the parameter is the ratio of the
corresponding sample quantiles and the following bootstrap procedure can be
used to find a confidence interval
when the population distribution is unspecified. The sample estimate is
recorded for each of \code{nSamples} bootstrap samples.  A bootstrap confidence
interval is given by $(l, u)$, where $l$ and $u$ are quantiles of the bootstrap
sampling distribution associated with $\alpha/2$ and $1-\alpha/2$,
respectively.  Although the nominal coverage is $1-\alpha$, interest lies in
computing the actual coverage probability of this bootstrap confidence interval
procedure using a Monte Carlo simulation study.  \code{nIntervals} samples from
the population are obtained from a user-supplied sampling function.  Although
the code is general, we sample $n=100$ observations from the standard normal
distribution and set $p_1=0.75$ and $p_2=0.35$, making $\beta_1/\beta_2 \approx
-1.75$.  We use \code{nIntervals} = 10,000 Monte Carlo replicates, each having
\code{nSamples} = 10,000 bootstrap samples.

The four implementations are available in the
Appendix, in the package, and at
{\footnotesize
\url{https://raw.githubusercontent.com/dbdahl/rscala/master/R/rscala/inst/doc/bootstrap-coverage.R}}.
The \R implementation is the shortest and the \rscala implementation
is somewhat more concise than the \Rcpp implementation.  The pure \R
iterates using apply functions.  The \Rcpp implementation is
written in \C style.  The pure \R, \Rcpp, and second \rscala implementations
use the \pkg{parallel} package to harness all available cores, whereas the
first \rscala implementation uses \Scala's \code{Future} class for parallelism.
In the first \rscala implementation, a single instance of \code{RClient} is
used by multiple JVM threads to call back to the single \R instance when
sampling the data.  On machines with many cores, having each thread wait its
turn to access the \R instance will likely slow down the execution.  In the
second \rscala implementation, each CPU core has a separate \R instance with a
corresponding \code{RClient}.

We tested on four machines running Ubuntu 16.04 with 8 cores, Ubuntu 16.04 with
56 cores, Mac Sierra with 8 cores, and Windows 10 with 8 cores.  \R was
compiled from source for the Ubuntu machines and was installed from binaries
downloaded from CRAN for the Mac and Windows machines.  All machines ran \R
3.4.1, \Scala 2.12.3, \Java 8, \Rcpp 0.12.12, and a prerelease version of
\rscala 2.3.1.

\begin{table}
\begin{center}
\begin{tabular}{c|lrrrrrr}
\toprule
Machine & Implementation&  Min.& $Q_1$&  Mean&Median& $Q_3$&   Max.\\
\midrule
\parbox[t]{4ex}{\multirow{4}{*}{\rotatebox[origin=c]{90}{\parbox{10ex}{\centering Ubuntu\\ 8 cores}}}}
   & Pure \R     & 1858.1 & 1863.9 & 1875.9 & 1867.9 & 1878.9 & 1943.8 \\
   & \Rcpp       &  105.1 &  105.3 &  107.3 &  105.6 &  106.5 &  118.6 \\
   & \rscala \#1 &   81.8 &   82.0 &   82.5 &   82.2 &   82.5 &   84.8 \\
   & \rscala \#2 &   70.2 &   70.4 &   71.4 &   70.7 &   70.9 &   77.9 \\
\midrule
\parbox[t]{4ex}{\multirow{4}{*}{\rotatebox[origin=c]{90}{\parbox{10ex}{\centering Ubuntu\\ 56 cores}}}}
  & Pure \R      &  444.1 &  449.8 &  450.8 &  451.3 &  452.4 &  456.1 \\
  & \Rcpp        &   19.7 &   19.6 &   19.7 &   19.8 &   19.8 &   20.0 \\
  & \rscala \#1  &   46.9 &   47.7 &   48.0 &   48.0 &   48.6 &   49.0 \\
  & \rscala \#2  &   14.5 &   14.6 &   16.6 &   14.8 &   15.0 &   32.2 \\
\midrule
\parbox[t]{4ex}{\multirow{4}{*}{\rotatebox[origin=c]{90}{\parbox{10ex}{\centering Mac\\ 8 cores}}}}
  & Pure \R      &        &        &        &        &        &        \\
  & \Rcpp        &  136.9 &  137.1 &  139.3 &  139.8 &  140.7 &  141.8 \\
  & \rscala \#1  &   93.4 &  94.2  &   94.7 &   94.9 &   95.3 &   95.8 \\
  & \rscala \#2  &   91.2 &  92.5  &   93.4 &   92.6 &   92.7 &  101.8 \\
\midrule
\parbox[t]{4ex}{\multirow{4}{*}{\rotatebox[origin=c]{90}{\parbox{10ex}{\centering Windows\\ 8 cores}}}}
  & Pure \R      &        &        &        &        &        &        \\
  & \Rcpp        &  184.8 &  185.0 &  187.6 &  185.3 &  186.1 &  201.8 \\
  & \rscala \#1  &  108.9 &  109.1 &  109.3 &  109.1 &  109.5 &  110.1 \\
  & \rscala \#2  &  106.7 &  107.3 &  107.8 &  107.9 &  108.0 &  109.9 \\
\bottomrule
\end{tabular}
\end{center}
\caption{Elapsed time (in seconds) for the four implementations of the
bootstrap simulation study executed on four different machines.  Overall, the
second \rscala implementation had the fastest execution times.}
\label{benchmarks}
\end{table}

Elapsed times (in seconds) for 10 replications of the simulation study are
found in Table \ref{benchmarks}.  For the sake of expediency, the pure \R
implementation was only run on the Ubuntu machines.  The pure \R implementation
ran more than 26 times slower than the fastest implementation.  The second
\rscala implementation (which uses the \pkg{parallel} package) was the fastest
overall.  The first \rscala implementation was close behind, except on the
Ubuntu machine with 56 cores, which illustrates the difficulty of sharing a
single \R instance across all of the cores.  The \Rcpp implementation is generally
slower than the \rscala implementations, but still much faster than
the pure \R implementation.

\section{Conclusion}
\label{conclusion}

This paper introduced the \rscala software to bridge \R and \Scala.  The
software allows a user to leverage their skills in both languages and to
utilize libraries and exploit strengths in each language.  For example, \R
users can implement computationally intensive algorithms in \Scala, write \R
packages based on \Scala, and access \Scala libraries from \R.  \Scala
programmers can take advantage of \R's tools for data analysis and graphics
from within a \Scala application. 

We are exploring two possible features to improve the package.  The first would
allow embedded \Scala computations to be interrupted by the \R user without
destroying the TCP/IP bridge.  The second feature would permit \R and \Scala to
run on separate machines.

\section*{Acknowledgements}

The author's work on this paper was supported by NIH NIGMS R01 GM104972.  The
author thanks the CRAN maintainers for their excellent service.  The author
also thanks the following students for valuable feedback on the software and
paper: Floid Gilbert, Brandon Carter, Deepthi Uppalapati, Scott Ferguson, and
Richard Payne.

\bibliography{refs}

\setcounter{section}{0}
\renewcommand{\thesection}{Appendix \Alph{section}}

\newpage
\section{}


{
\footnotesize
\VerbatimInput[numbers=left,xleftmargin=5mm]{../inst/doc/bootstrap-coverage.R}
}

\end{document}

<<closeScala,eval=TRUE,include=FALSE>>=
close(s)
@

